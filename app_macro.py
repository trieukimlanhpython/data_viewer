# app_macro_viewer.py
# -*- coding: utf-8 -*-
"""
Created on Thu Oct 30 2025
@author: trieukimlanh
üåç ·ª®ng d·ª•ng xem d·ªØ li·ªáu vƒ© m√¥ World Bank + CSV + Google Sheet
streamlit run "/Users/trieukimlanh/Library/CloudStorage/GoogleDrive-lanhtk@hub.edu.vn/My Drive/Spyder/macro/app_macro.py"
"""
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from pandas_datareader import wb
import numpy as np
import datetime as dt
from io import BytesIO
import re
from packaging.version import Version
LooseVersion = Version

# ==========================================================
# ‚öôÔ∏è CONFIG
# ==========================================================
st.set_page_config(page_title="üåç Macro Data Viewer (World Bank)", layout="wide")
st.title("üìä Macro Data Explorer")
st.sidebar.header("üåé T√πy ch·ªçn d·ªØ li·ªáu")

# ==========================================================
# üß© NGU·ªíN D·ªÆ LI·ªÜU
# ==========================================================
data_source = st.sidebar.radio(
    "Ngu·ªìn d·ªØ li·ªáu:",
    ["World Bank", "Upload CSV", "Google Sheet", "K·∫øt h·ª£p (World Bank + CSV/GS)"],
)

df_all = None
all_data = {}

# ==========================================================
# üìÅ H√ÄM H·ªñ TR·ª¢
# ==========================================================
def prepare_csv(df):
    date_col = next((c for c in df.columns if c.lower() in ["date", "year", "time"]), None)
    if date_col:
        col_data = df[date_col]
        if pd.api.types.is_integer_dtype(col_data) or pd.api.types.is_float_dtype(col_data):
            df["Date"] = pd.to_datetime(col_data.astype(int).astype(str) + "-01-01")
        else:
            df["Date"] = pd.to_datetime(col_data, errors="coerce")

        # Kh√¥ng l·ªçc m·∫•t c√°c c·ªôt kh√°c ‚Äî ch·ªâ set index
        df = df.set_index("Date").sort_index()

        # Th·ª≠ √©p ki·ªÉu numeric cho c√°c c·ªôt c√≤n l·∫°i n·∫øu c√≥ th·ªÉ
        for col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="ignore")

    else:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt th·ªùi gian (Date/Year/Time).")

    return df


def load_csv_files(uploaded_files):
    dfs = []
    for file in uploaded_files:
        try:
            df = pd.read_csv(file)
            df_prepared = prepare_csv(df)
            dfs.append(df_prepared)
        except Exception as e:
            st.warning(f"L·ªói ƒë·ªçc file {file.name}: {e}")
    if dfs:
        df_csv = pd.concat(dfs, axis=1).dropna(how="all").sort_index()
        st.sidebar.success("‚úÖ ƒê·ªçc CSV th√†nh c√¥ng!")
        return df_csv
    return None

def read_gsheet_precise(sheet_link):
    """ƒê·ªçc Google Sheet d·∫°ng CSV, t·ª± ƒë·ªông nh·∫≠n di·ªán c·ªôt v√† d·ªØ li·ªáu d·∫°ng s·ªë/ch·ªØ."""
    try:
        # Chu·∫©n ho√° link export
        base_id = None
        gid = "0"
        if "/d/" in sheet_link:
            parts = sheet_link.split("/d/")
            base_id = parts[1].split("/")[0]
            if "gid=" in sheet_link:
                gid = sheet_link.split("gid=")[-1].split("&")[0].split("#")[0]
        if not base_id:
            st.warning("‚ö†Ô∏è Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c ID c·ªßa Google Sheet.")
            return None

        csv_url = f"https://docs.google.com/spreadsheets/d/{base_id}/export?format=csv&gid={gid}"

        # Th·ª≠ ƒë·ªçc CSV, n·∫øu l·ªói d·∫•u th·∫≠p ph√¢n th√¨ fallback
        try:
            df = pd.read_csv(csv_url)
        except Exception:
            df = pd.read_csv(csv_url, decimal=",", thousands=".")

        # L√†m s·∫°ch t√™n c·ªôt
        df.columns = [str(c).strip() for c in df.columns]

        # Chuy·ªÉn % v√† d·∫•u ph·∫©y sang s·ªë n·∫øu c·∫ßn
        for col in df.columns:
            if df[col].dtype == object:
                series = df[col].astype(str).str.strip()
                
                # N·∫øu c·ªôt n√†y c√≥ >70% gi√° tr·ªã l√† s·ªë (sau khi b·ªè k√Ω t·ª±), th√¨ x·ª≠ l√Ω nh∆∞ s·ªë
                numeric_like = series.str.replace(r"[^0-9,.\-%]", "", regex=True)
                ratio_numeric = numeric_like.apply(lambda x: x.replace(",", ".").replace("%", "").replace("-", "").replace(".", "").isdigit()).mean()
        
                if ratio_numeric > 0.7:
                    series = (
                        series
                        .str.replace("%", "", regex=False)
                        .str.replace(",", ".", regex=False)
                        .str.replace(" ", "", regex=False)   # ch·ªâ xo√° khi l√† d·∫°ng s·ªë
                    )
                    df[col] = pd.to_numeric(series, errors="ignore")
                else:
                    # N·∫øu l√† text, gi·ªØ nguy√™n kho·∫£ng tr·∫Øng
                    df[col] = series


        df_prepared = prepare_csv(df)
        return df_prepared

    except Exception as e:
        st.warning(f"‚ùå L·ªói ƒë·ªçc Google Sheet: {e}")
        return None



def load_wb_data(countries, indicators, start_year, end_year):
    try:
        df_wb = wb.download(indicator=indicators, country=countries, start=start_year, end=end_year)
        df_wb = df_wb.reset_index()
        df_wb = df_wb.pivot(index="year", columns=["country"], values=indicators)
        if isinstance(df_wb.columns, pd.MultiIndex):
            df_wb.columns = [f"{col[1]}_{col[0]}" for col in df_wb.columns]
        else:
            df_wb.columns = [str(col) for col in df_wb.columns]
        df_wb.index = pd.to_datetime(df_wb.index, format="%Y", errors='coerce')
        df_wb = df_wb.sort_index()
        st.sidebar.success("‚úÖ T·∫£i d·ªØ li·ªáu World Bank th√†nh c√¥ng!")
        return df_wb
    except Exception as e:
        st.error(f"L·ªói t·∫£i World Bank: {e}")
        return None

# ==========================================================
# üìù SIDEBAR TRA C·ª®U & NH·∫¨P D·ªÆ LI·ªÜU
# ==========================================================
if data_source in ["World Bank", "K·∫øt h·ª£p (World Bank + CSV/GS)"]:
    st.sidebar.subheader("üåé Tra c·ª©u World Bank")

    # Tra c·ª©u ch·ªâ ti√™u
    with st.sidebar.expander("üîé Tra c·ª©u ch·ªâ ti√™u (Indicator)"):
        search_term = st.text_input("Nh·∫≠p t·ª´ kh√≥a (VD: gdp, inflation, export...)", "gdp per capita")
        if st.button("T√¨m ch·ªâ ti√™u", key="search_indicator"):
            try:
                results = wb.search(search_term)
                st.write(results[['id','name','sourceNote']].head(20))
                st.success(f"T√¨m th·∫•y {len(results)} ch·ªâ ti√™u li√™n quan.")
            except Exception as e:
                st.error(f"L·ªói t√¨m ki·∫øm: {e}")
            st.info("D√πng c·ªôt `id` l√†m m√£ ch·ªâ ti√™u t·∫£i v·ªÅ (VD: NY.GDP.PCAP.CD).")

    # Nh·∫≠p m√£ ch·ªâ ti√™u
    indicator_input = st.sidebar.text_area(
        "M√£ ch·ªâ ti√™u (VD: NY.GDP.MKTP.KD.ZG, FP.CPI.TOTL.ZG):",
        "NY.GDP.MKTP.KD.ZG\nFP.CPI.TOTL.ZG"
    )
    st.session_state["indicator_input"] = indicator_input

    # Hi·ªÉn th·ªã m√¥ t·∫£ ch·ªâ ti√™u ƒë√£ nh·∫≠p
    indicator_list = [ind.strip() for ind in indicator_input.splitlines() if ind.strip()]
    if indicator_list:
        try:
            all_indicators = wb.get_indicators()
            matched = all_indicators[all_indicators["id"].isin(indicator_list)]
            if not matched.empty:
                st.sidebar.subheader("üìò M√¥ t·∫£ ch·ªâ ti√™u")
                for _, row in matched.iterrows():
                    with st.sidebar.expander(f"{row['id']} ‚Äî {row['name']}"):
                        if isinstance(row['sourceNote'], str) and row['sourceNote']:
                            st.write(row['sourceNote'])
                        else:
                            st.write("Kh√¥ng c√≥ m√¥ t·∫£ th√™m.")
            else:
                st.sidebar.info("Kh√¥ng t√¨m th·∫•y m√¥ t·∫£ cho m√£ nh·∫≠p v√†o.")
        except Exception as e:
            st.sidebar.warning(f"L·ªói khi tra m√¥ t·∫£ ch·ªâ ti√™u: {e}")

    # Nh·∫≠p qu·ªëc gia
    country_input = st.sidebar.text_input("M√£ qu·ªëc gia (VD: VN, US, CN):", "VN,US")
    st.session_state["country_input"] = country_input

    # Ch·ªçn kho·∫£ng th·ªùi gian
    start_year_date = st.sidebar.date_input("T·ª´ ng√†y (World Bank)", dt.date(2000,1,1),
                                            min_value=dt.date(1960,1,1), max_value=dt.date.today())
    end_year_date = st.sidebar.date_input("ƒê·∫øn ng√†y (World Bank)", dt.date.today(),
                                          min_value=dt.date(1960,1,1), max_value=dt.date.today())
    st.session_state["start_year"] = start_year_date.year
    st.session_state["end_year"] = end_year_date.year

# CSV / Google Sheet upload
# ==========================================================
# üì• NH·∫¨P D·ªÆ LI·ªÜU CSV / GOOGLE SHEET
# ==========================================================
uploaded_files = []
gsheet_links = []

# Cho ph√©p nh·∫≠p CSV ho·∫∑c Google Sheet trong c·∫£ 3 tr∆∞·ªùng h·ª£p:
# "Upload CSV", "Google Sheet", "K·∫øt h·ª£p (World Bank + CSV/GS)"
if data_source in ["Upload CSV", "Google Sheet", "K·∫øt h·ª£p (World Bank + CSV/GS)"]:
    st.sidebar.subheader("üìÅ D·ªØ li·ªáu ch√≠nh")

    # Upload CSV (t√πy ch·ªçn)
    if data_source in ["Upload CSV", "K·∫øt h·ª£p (World Bank + CSV/GS)"]:
        uploaded_files = st.sidebar.file_uploader(
            "üìÇ Upload file CSV (c√≥ c·ªôt Date/Year/Time)",
            type="csv",
            accept_multiple_files=True
        )

    # Nh·∫≠p link Google Sheet (t√πy ch·ªçn)
    # ---- D·ªØ li·ªáu Google Sheet ----
    if data_source in ["Google Sheet", "K·∫øt h·ª£p (World Bank + CSV/GS)"]:
        st.sidebar.markdown("üåê **Ho·∫∑c nh·∫≠p link Google Sheet D·ªÆ LI·ªÜU** (m·ªói link 1 d√≤ng)")
        gsheet_data_input = st.sidebar.text_area(
            "üîó Link Google Sheet d·ªØ li·ªáu:",
            placeholder="https://docs.google.com/spreadsheets/d/xxxxxx/edit#gid=0",
            key="gsheet_data_input_data"  # üëà ƒë·ªïi key
        )
        gsheet_links = [link.strip() for link in gsheet_data_input.splitlines() if link.strip()]
    else:
        gsheet_links = []  # üëà reset r√µ r√†ng khi kh√¥ng d√πng

    
    # ‚Äî‚Äî‚Äî NgƒÉn c√°ch r√µ ph·∫ßn m√¥ t·∫£ ‚Äî
    st.sidebar.divider()


# ==========================================================
# üìÅ NH·∫¨P FILE M√î T·∫¢ (indicator & unit)
# ==========================================================
st.sidebar.subheader("üìÑ D·ªØ li·ªáu m√¥ t·∫£")

# 1Ô∏è‚É£ Upload CSV m√¥ t·∫£
desc_file = st.sidebar.file_uploader("Ch·ªçn file CSV m√¥ t·∫£", type="csv")

# 2Ô∏è‚É£ Link Google Sheet m√¥ t·∫£
gs_desc_link = st.sidebar.text_input(
    "Ho·∫∑c d√°n link Google Sheet m√¥ t·∫£ (1 link)",
    placeholder="https://docs.google.com/spreadsheets/d/xxxxxx/edit#gid=0",
    key="gsheet_data_input_desc"
)

unit_map = {}
df_desc = pd.DataFrame()

if desc_file:
    try:
        df_desc = pd.read_csv(desc_file)
        if 'indicator' in df_desc.columns and 'unit' in df_desc.columns:
            unit_map = dict(zip(df_desc['indicator'], df_desc['unit']))
        else:
            st.warning("‚ö†Ô∏è File m√¥ t·∫£ ph·∫£i c√≥ c·ªôt 'indicator' v√† 'unit'.")
    except Exception as e:
        st.warning(f"‚ùå L·ªói ƒë·ªçc file m√¥ t·∫£: {e}")

elif gs_desc_link.strip():
    try:
        df_desc = read_gsheet_precise(gs_desc_link)
        if 'indicator' in df_desc.columns and 'unit' in df_desc.columns:
            unit_map = dict(zip(df_desc['indicator'], df_desc['unit']))
        else:
            st.warning("‚ö†Ô∏è Google Sheet m√¥ t·∫£ ph·∫£i c√≥ c·ªôt 'indicator' v√† 'unit'.")
    except Exception as e:
        st.warning(f"‚ùå L·ªói ƒë·ªçc Google Sheet m√¥ t·∫£: {e}")

# ‚úÖ Ch·ªâ hi·ªÉn th·ªã b·∫£ng m√¥ t·∫£ ·ªü ƒë√¢y m·ªôt l·∫ßn
if not df_desc.empty:
    st.markdown("### üìä Th√¥ng tin m√¥ t·∫£")
    st.dataframe(df_desc, height=180, use_container_width=True)


# ==========================================================
# ‚ñ∂Ô∏è T·∫¢I & HI·ªÇN TH·ªä D·ªÆ LI·ªÜU
# ==========================================================
if st.button("üöÄ T·∫£i & Hi·ªÉn th·ªã d·ªØ li·ªáu"):

    all_data = {}
    total_unit_map = {}
    total_name_map = {}

    # ----------------------------
    # 1Ô∏è‚É£ WORLD BANK
    # ----------------------------
    if data_source in ["World Bank", "K·∫øt h·ª£p (World Bank + CSV/GS)"]:
        countries = [c.strip().upper() for c in st.session_state.get("country_input", "VN,US").split(",")]
        indicators = [ind.strip() for ind in st.session_state.get("indicator_input", "").splitlines() if ind.strip()]
        start_year = st.session_state.get("start_year", 2000)
        end_year = st.session_state.get("end_year", 2024)

        try:
            # T·∫£i d·ªØ li·ªáu WB
            df_wb = wb.download(indicator=indicators, country=countries, start=start_year, end=end_year)
            df_wb = df_wb.reset_index().pivot(index="year", columns=["country"], values=indicators)
            if isinstance(df_wb.columns, pd.MultiIndex):
                df_wb.columns = [f"{col[1]}_{col[0]}" for col in df_wb.columns]
            else:
                df_wb.columns = [str(col) for col in df_wb.columns]
            df_wb.index = pd.to_datetime(df_wb.index, format="%Y", errors='coerce')
            df_wb = df_wb.sort_index()
            st.sidebar.success("‚úÖ T·∫£i d·ªØ li·ªáu World Bank th√†nh c√¥ng!")

            # L·∫•y unit / name t·ª´ meta
            df_meta = wb.get_indicators()
            for ind in indicators:
                row = df_meta[df_meta["id"] == ind]
                if not row.empty:
                    name = row.iloc[0]["name"]
                    note = row.iloc[0]["sourceNote"]
                    # Suy ƒëo√°n ƒë∆°n v·ªã
                    match = re.search(r"\((.*?)\)", name)
                    unit = match.group(1) if match else None
                    if not unit and isinstance(note, str):
                        match = re.search(r"\((.*?)\)", note)
                        if match:
                            unit = match.group(1)
                        elif "percent" in note.lower():
                            unit = "%"
                    # √Åp map theo c·ªôt
                    for col in df_wb.columns:
                        if col.endswith(f"_{ind}"):
                            total_unit_map[col] = unit or ""
                            total_name_map[col] = name
            all_data["WorldBank"] = df_wb

        except Exception as e:
            st.error(f"‚ùå L·ªói t·∫£i World Bank: {e}")

    # ----------------------------
    # 2Ô∏è‚É£ CSV
    # ----------------------------
    if uploaded_files:
        df_csv = load_csv_files(uploaded_files)
        if df_csv is not None:
            all_data["CSV"] = df_csv
            # L·∫•y unit t·ª´ file m√¥ t·∫£ n·∫øu c√≥
            for c in df_csv.columns:
                if c in unit_map:
                    total_unit_map[c] = unit_map[c]
                else:
                    total_unit_map[c] = ""
                total_name_map[c] = c

    # ----------------------------
    # 3Ô∏è‚É£ GOOGLE SHEET D·ªÆ LI·ªÜU
    # ----------------------------
    for link in gsheet_links:
        if link.strip():
            try:
                df_gs = read_gsheet_precise(link)
                # ƒê·∫∑t t√™n ri√™ng cho t·ª´ng sheet theo ID + GID
                sheet_id = re.search(r"/d/([^/]+)/", link).group(1)
                gid_match = re.search(r"gid=(\d+)", link)
                gid = gid_match.group(1) if gid_match else "0"
                sheet_name = f"GS_{sheet_id}_{gid}"
    
                all_data[sheet_name] = df_gs
                for c in df_gs.columns:
                    total_unit_map[c] = unit_map.get(c, "")
                    total_name_map[c] = c
    
            except Exception as e:
                st.warning(f"‚ùå L·ªói ƒë·ªçc Google Sheet d·ªØ li·ªáu: {e}")


    # ----------------------------
    # ‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu
    # ----------------------------
    if not all_data:
        st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c t·∫£i.")
        st.stop()

    # ----------------------------
    # üîÄ G·ªòP D·ªÆ LI·ªÜU
    # ----------------------------
    common_cols = ['Date', 'date', 'year', 'time']
    merge_col = None
    for col in common_cols:
        if all(col in df.columns for df in all_data.values()):
            merge_col = col
            break

    if merge_col:
        from functools import reduce
        df_all = reduce(lambda left, right: pd.merge(left, right, on=merge_col, how='outer'), all_data.values())
        st.success(f"‚úÖ H·ª£p nh·∫•t d·ªØ li·ªáu theo c·ªôt `{merge_col}`")
    else:
        # ƒê·∫£m b·∫£o index c·ªßa t·ª´ng DataFrame l√† duy nh·∫•t
        for k, v in all_data.items():
            if not v.index.is_unique:
                v = v[~v.index.duplicated(keep='first')]
                all_data[k] = v
        
        # Sau ƒë√≥ m·ªõi concat
        df_all = pd.concat(all_data.values(), axis=1, join='outer').dropna(how='all')

        st.info("‚ÑπÔ∏è Hi·ªÉn th·ªã d·ªØ li·ªáu ƒë√£ t·∫£i l√™n")

    # ----------------------------
    # üíæ L∆∞u v√†o session
    # ----------------------------
    st.session_state["df_all"] = df_all
    st.session_state["unit_map"] = total_unit_map
    st.session_state["name_map"] = total_name_map

    # ----------------------------
    # üìã Hi·ªÉn th·ªã d·ªØ li·ªáu
    # ----------------------------
    #st.dataframe(df_all)
    # Chu·∫©n ho√° hi·ªÉn th·ªã c·ªôt th·ªùi gian
    df_display = df_all.copy()
    if isinstance(df_display.index, pd.DatetimeIndex):
        df_display.index = df_display.index.strftime("%Y-%m-%d")

    st.markdown("### üìä D·ªØ li·ªáu")
    st.dataframe(df_display, height=180, use_container_width=True)
    
    st.markdown("### üßæ Th·ªëng k√™ m√¥ t·∫£ d·ªØ li·ªáu")
    st.dataframe(df_display.describe(), height=180, use_container_width=True)

    st.sidebar.success(f"‚úÖ T·ªïng {len(df_all.columns)} c·ªôt d·ªØ li·ªáu ƒë√£ t·∫£i.")




# ==========================================================
# üìä V·∫º D·ªÆ LI·ªÜU (c√≥ tu·ª≥ ch·ªânh th·ªùi gian & t·∫ßn su·∫•t)
# ==========================================================
if "df_all" in st.session_state:
    df_plot = st.session_state["df_all"]
    st.subheader("üìä T√πy ch·ªânh v√† V·∫Ω bi·ªÉu ƒë·ªì")

    # ========== üïí Ch·ªçn kho·∫£ng th·ªùi gian ==========
    st.markdown("### üïí L·ªçc th·ªùi gian hi·ªÉn th·ªã")
    # ƒê·∫£m b·∫£o index c√≥ ki·ªÉu datetime
    if not isinstance(df_plot.index, pd.DatetimeIndex):
        if "Date" in df_plot.columns:
            df_plot["Date"] = pd.to_datetime(df_plot["Date"], errors="coerce", format="%Y", exact=False)
            df_plot = df_plot.set_index("Date")
        else:
            st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt 'Date' trong d·ªØ li·ªáu CSV.")
            st.stop()
    
    # N·∫øu d·ªØ li·ªáu ch·ªâ c√≥ nƒÉm, ƒëi·ªÅn m·∫∑c ƒë·ªãnh l√† ng√†y 1/1
    if df_plot.index.dtype == 'datetime64[ns]':
        df_plot.index = df_plot.index.fillna(pd.Timestamp("1900-01-01"))
    
    # Lo·∫°i b·ªè NaT trong index
    df_plot = df_plot[~df_plot.index.isna()]
    
    if not df_plot.empty:
        min_date = df_plot.index.min().date()
        max_date = df_plot.index.max().date()
    else:
        st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi x·ª≠ l√Ω c·ªôt th·ªùi gian.")
        st.stop()

    if isinstance(df_plot.index, pd.DatetimeIndex):
        min_date = df_plot.index.min().date()
        max_date = df_plot.index.max().date()

        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("T·ª´ ng√†y:", min_date, min_value=min_date, max_value=max_date)
        with col2:
            end_date = st.date_input("ƒê·∫øn ng√†y:", max_date, min_value=min_date, max_value=max_date)

        # L·ªçc b·ªè gi√° tr·ªã th·ªùi gian NaT tr∆∞·ªõc khi so s√°nh
        if isinstance(df_plot.index, pd.DatetimeIndex):
            df_plot = df_plot[~df_plot.index.isna()]
        
            mask = (df_plot.index >= pd.to_datetime(start_date)) & (df_plot.index <= pd.to_datetime(end_date))
            df_plot = df_plot.loc[mask]

    else:
        st.info("D·ªØ li·ªáu ch∆∞a c√≥ ƒë·ªãnh d·∫°ng th·ªùi gian, hi·ªÉn th·ªã to√†n b·ªô.")

    # ========== ‚è≥ Ch·ªçn t·∫ßn su·∫•t ==========
    st.markdown("### ‚è≥ Ch·ªçn t·∫ßn su·∫•t v·∫Ω d·ªØ li·ªáu")
    freq_map = {
        "NƒÉm": "Y",
        "Qu√Ω": "Q",
        "Th√°ng": "M",
        "Tu·∫ßn": "W",
        "Ng√†y": "D"
    }
    freq_choice = st.radio("T·∫ßn su·∫•t hi·ªÉn th·ªã:", list(freq_map.keys()), horizontal=True)
    freq_code = freq_map[freq_choice]

    if isinstance(df_plot.index, pd.DatetimeIndex):
        # Gi·ªØ c·ªôt numeric ri√™ng ƒë·ªÉ t√≠nh
        df_num = df_plot.select_dtypes(include="number")
        
        # N·∫øu c√≥ c·ªôt text, l∆∞u l·∫°i ƒë·ªÉ merge sau
        df_nonnum = df_plot.select_dtypes(exclude="number")
        
        # Resample ch·ªâ ph·∫ßn numeric
        df_resampled = df_num.resample(freq_code).mean()
        
        # G·∫Øn l·∫°i c·ªôt text n·∫øu c·∫ßn (gi·ªØ gi√° tr·ªã ƒë·∫ßu ti√™n c·ªßa m·ªói giai ƒëo·∫°n)
        if not df_nonnum.empty:
            df_text = df_nonnum.resample(freq_code).first()
            df_plot = pd.concat([df_resampled, df_text], axis=1)
        else:
            df_plot = df_resampled


    # ========== üß© Ch·ªçn c·ªôt ƒë·ªÉ v·∫Ω ==========
    st.markdown("### üß© Ch·ªçn ch·ªâ ti√™u hi·ªÉn th·ªã")
    # T·ª± ƒë·ªông nh·∫≠n di·ªán c·ªôt c√≥ th·ªÉ l√† numeric
    cols_to_plot = st.multiselect(
        "Ch·ªçn c·ªôt d·ªØ li·ªáu ƒë·ªÉ v·∫Ω:",
        options=df_plot.columns.tolist(),
        default=df_plot.columns[:3].tolist() if len(df_plot.columns) >= 3 else df_plot.columns.tolist()
    )

    if cols_to_plot:
        #df_subset = df_plot[cols_to_plot].dropna(how="all")
        df_subset = df_plot[cols_to_plot].dropna(how="any")
        fig, ax = plt.subplots(figsize=(12, 5))

        # Ph√¢n tr·ª•c d·ª±a theo ƒë∆°n v·ªã (n·∫øu c√≥)
        unit_map = st.session_state.get("unit_map", {})
        name_map = st.session_state.get("name_map", {})
        left_cols, right_cols = [], []
        left_names, right_names = {}, {}

        if unit_map:
            units = [unit_map.get(col, None) for col in cols_to_plot]
            unique_units = list(set([u for u in units if u]))

            if len(unique_units) > 1:
                left_unit = unique_units[0]
                for col in cols_to_plot:
                    name_label = name_map.get(col, col)
                    if unit_map.get(col) == left_unit:
                        left_cols.append(col)
                        left_names[col] = name_label
                    else:
                        right_cols.append(col)
                        right_names[col] = name_label
            else:
                left_cols = cols_to_plot
                left_names = {col: name_map.get(col, col) for col in left_cols}
        else:
            left_cols = cols_to_plot
            left_names = {col: col for col in left_cols}

        # ======== V·∫Ω tr·ª•c tr√°i ========
        colors_left = plt.cm.Set2(np.linspace(0, 1, len(left_cols)))
        for i, col in enumerate(left_cols):
            ax.plot(
                df_subset.index, df_subset[col],
                label=left_names[col],
                color=colors_left[i],
                linewidth=2
            )
        ax.set_ylabel(", ".join([left_names[c] for c in left_cols]), color="tab:blue")
        ax.tick_params(axis='y', labelcolor="tab:blue")
        ax.set_xlabel("Th·ªùi gian")
        ax.grid(alpha=0.3)
        
        # ======== V·∫Ω tr·ª•c ph·∫£i (n·∫øu c√≥) ========
        if right_cols:
            ax2 = ax.twinx()
            colors_right = plt.cm.Set1(np.linspace(0, 1, len(right_cols)))
            for i, col in enumerate(right_cols):
                ax2.plot(
                    df_subset.index, df_subset[col],
                    linestyle='--',
                    label=right_names[col],
                    color=colors_right[i],
                    linewidth=2
                )
            ax2.set_ylabel(", ".join([right_names[c] for c in right_cols]), color="tab:red")
            ax2.tick_params(axis='y', labelcolor="tab:red")
        
            # G·ªôp legend c·ªßa c·∫£ 2 tr·ª•c
            lines1, labels1 = ax.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=8)
        else:
            ax.legend(fontsize=8)


        # ======== Ti√™u ƒë·ªÅ bi·ªÉu ƒë·ªì ========
        title_parts = []
        if left_cols:
            title_parts.append(", ".join([left_names[c] for c in left_cols]))
        if right_cols:
            title_parts.append(", ".join([right_names[c] for c in right_cols]))
        ax.set_title(" & ".join(title_parts), fontsize=14)

        st.pyplot(fig)

        # ========== üíæ T·∫£i d·ªØ li·ªáu l·ªçc ra ==========
        csv_export = df_subset.reset_index().to_csv(index=False).encode("utf-8")
        st.download_button(
            "üíæ T·∫£i d·ªØ li·ªáu hi·ªÉn th·ªã (CSV)",
            csv_export,
            file_name="filtered_plot_data.csv",
            mime="text/csv"
        )


